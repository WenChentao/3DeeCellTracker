{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69c2956",
   "metadata": {},
   "source": [
    "# 3DeeCellTracker Demo: Train FlexiblePointMatcher with a .csv file\n",
    "\n",
    "This notebook shows how to train a neural network called FlexiblePointMatching for 3D cell tracking. \n",
    "\n",
    "To get started, you can download the \"worm3_points_t1.csv\" file from our GitHub repository at https://github.com/WenChentao/3DeeCellTracker/blob/master/Examples/use_stardist/worm3_points_t1.csv. This file will be used throughout the notebook to showcase the FFN training process. Alternatively, you can generate your own 3D cell coordinates in a .csv file to train your own model.\n",
    "\n",
    "**The basic procedures:**\n",
    "- A. Import packages\n",
    "- B. Initialize the trainer\n",
    "- C. Train FPM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d800eb",
   "metadata": {},
   "source": [
    "## A. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ead6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "from CellTracker.fpm import TrainFPM, FlexiblePointMatcherEuclideanDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a60678",
   "metadata": {},
   "source": [
    "## B. Train FPM\n",
    "\n",
    "### Parameters\n",
    "- `points_path`: A string that specifies the path to the .csv file containing the 3D cell coordinates.\n",
    "- `model_name`: A string specifying the name of the ffn model to save. This name will be used to load the model later.\n",
    "\n",
    "### Notes:\n",
    "> By default, the trained model will be saved in the \"ffn_models\" directory. If you want to save the model in a different location, you can specify the basedir parameter and provide the directory path.\n",
    "```\n",
    "    ffn_trainer = TrainFFN(points1_path=points_path, model_name=model_name, basedir=\".\\FolderA\\FolderB\\\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7b7dc",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "- `num_epochs`: An integer specifying the number of epochs for training. A larger number of epochs will require a longer training time. The default value of 100 is a reasonable choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa17c51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 5001batch [02:09, 38.69batch/s, Train Accuracy=0.575, Train loss=0.682]\n",
      "Epoch 2/100:  25%|‚ñè| 1230/5000 [00:31<01:37, 38.60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23428\\3680465376.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpoints_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./worm3_points_t1.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fpm_add_2skip_ed_worm3_180_deg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdeg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m180\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chint\\pycharmprojects\\3deecelltracker\\CellTracker\\fpm.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, num_epochs, iteration, weights_name)\u001b[0m\n\u001b[0;32m     96\u001b[0m                     \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Train loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Train Accuracy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_model\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34mf'{weights_name}_epoch{epoch}.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stardist\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_gradients\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1072\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stardist\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     67\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     raise ValueError(\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stardist\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stardist\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    587\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           data_format=data_format),\n\u001b[1;32m--> 591\u001b[1;33m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0m\u001b[0;32m    592\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m           \u001b[0mshape_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stardist\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1084\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m       return conv2d_backprop_filter_eager_fallback(\n\u001b[0;32m   1091\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "points_path=\"./worm3_points_t1.csv\"\n",
    "model_name=\"fpm_add_2skip_ed_worm3_180_deg\"\n",
    "deg = 180\n",
    "num_epochs=100\n",
    "match_model = FlexiblePointMatcherEuclideanDist(num_skip=2)\n",
    "\n",
    "fpm_trainer = TrainFPM(points1_path=points_path, match_model=match_model, model_name=model_name, \n",
    "                       range_rotation_tgt=deg)\n",
    "fpm_trainer.train(num_epochs=num_epochs, iteration=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21192d8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 17:20:44.036178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.040086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.040486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.041003: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 17:20:44.041403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.041830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.042243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.293491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.293912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.294274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-05 17:20:44.294619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10035 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Epoch 1/100:   0%|    | 0/5000 [00:00<?, ?batch/s]2023-07-05 17:20:44.825775: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2023-07-05 17:20:45.493987: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Epoch 1/100: 5001batch [01:31, 54.86batch/s, Train Accuracy=0.867, Train loss=0.204]\n",
      "Epoch 2/100: 5001batch [01:28, 56.23batch/s, Train Accuracy=0.921, Train loss=0.149]\n",
      "Epoch 3/100: 5001batch [01:30, 55.01batch/s, Train Accuracy=0.93, Train loss=0.139]\n",
      "Epoch 4/100: 5001batch [01:31, 54.69batch/s, Train Accuracy=0.935, Train loss=0.125]\n",
      "Epoch 5/100: 5001batch [01:25, 58.16batch/s, Train Accuracy=0.939, Train loss=0.119]\n",
      "Epoch 6/100: 5001batch [01:26, 57.97batch/s, Train Accuracy=0.942, Train loss=0.115]\n",
      "Epoch 7/100: 5001batch [01:25, 58.17batch/s, Train Accuracy=0.944, Train loss=0.114]\n",
      "Epoch 8/100: 5001batch [01:25, 58.25batch/s, Train Accuracy=0.946, Train loss=0.11]\n",
      "Epoch 9/100: 5001batch [01:26, 58.14batch/s, Train Accuracy=0.947, Train loss=0.107]\n",
      "Epoch 10/100: 5001batch [01:26, 57.90batch/s, Train Accuracy=0.948, Train loss=0.107]\n",
      "Epoch 11/100: 5001batch [01:25, 58.21batch/s, Train Accuracy=0.949, Train loss=0.106]\n",
      "Epoch 12/100: 5001batch [01:26, 58.08batch/s, Train Accuracy=0.95, Train loss=0.102]\n",
      "Epoch 13/100: 5001batch [01:26, 57.92batch/s, Train Accuracy=0.951, Train loss=0.106]\n",
      "Epoch 14/100: 5001batch [01:26, 58.00batch/s, Train Accuracy=0.951, Train loss=0.104]\n",
      "Epoch 15/100: 5001batch [01:25, 58.17batch/s, Train Accuracy=0.952, Train loss=0.102]\n",
      "Epoch 16/100: 5001batch [01:25, 58.72batch/s, Train Accuracy=0.953, Train loss=0.104]\n",
      "Epoch 17/100: 5001batch [01:22, 60.98batch/s, Train Accuracy=0.953, Train loss=0.102]\n",
      "Epoch 18/100: 5001batch [01:21, 61.04batch/s, Train Accuracy=0.953, Train loss=0.101]\n",
      "Epoch 19/100: 5001batch [01:21, 61.06batch/s, Train Accuracy=0.954, Train loss=0.0982]\n",
      "Epoch 20/100: 5001batch [01:22, 60.91batch/s, Train Accuracy=0.954, Train loss=0.103]\n",
      "Epoch 21/100: 5001batch [01:21, 61.18batch/s, Train Accuracy=0.954, Train loss=0.0994]\n",
      "Epoch 22/100: 5001batch [01:21, 61.03batch/s, Train Accuracy=0.955, Train loss=0.103]\n",
      "Epoch 23/100: 5001batch [01:21, 61.26batch/s, Train Accuracy=0.955, Train loss=0.101]\n",
      "Epoch 24/100: 5001batch [01:22, 60.82batch/s, Train Accuracy=0.955, Train loss=0.101]\n",
      "Epoch 25/100: 5001batch [01:21, 61.14batch/s, Train Accuracy=0.955, Train loss=0.0992]\n",
      "Epoch 26/100: 5001batch [01:22, 60.92batch/s, Train Accuracy=0.956, Train loss=0.0977]\n",
      "Epoch 27/100: 5001batch [01:21, 61.04batch/s, Train Accuracy=0.956, Train loss=0.0964]\n",
      "Epoch 28/100: 5001batch [01:21, 61.02batch/s, Train Accuracy=0.956, Train loss=0.0987]\n",
      "Epoch 29/100: 5001batch [01:21, 61.22batch/s, Train Accuracy=0.956, Train loss=0.0995]\n",
      "Epoch 30/100: 5001batch [01:21, 61.13batch/s, Train Accuracy=0.956, Train loss=0.0992]\n",
      "Epoch 31/100: 5001batch [01:23, 59.73batch/s, Train Accuracy=0.957, Train loss=0.0967]\n",
      "Epoch 32/100: 5001batch [01:26, 58.07batch/s, Train Accuracy=0.957, Train loss=0.0973]\n",
      "Epoch 33/100: 5001batch [01:26, 57.88batch/s, Train Accuracy=0.957, Train loss=0.0984]\n",
      "Epoch 34/100: 5001batch [01:26, 57.97batch/s, Train Accuracy=0.957, Train loss=0.0972]\n",
      "Epoch 35/100: 5001batch [01:25, 58.25batch/s, Train Accuracy=0.957, Train loss=0.0989]\n",
      "Epoch 36/100: 5001batch [01:25, 58.33batch/s, Train Accuracy=0.957, Train loss=0.0967]\n",
      "Epoch 37/100: 5001batch [01:26, 57.92batch/s, Train Accuracy=0.958, Train loss=0.0953]\n",
      "Epoch 38/100: 5001batch [01:25, 58.24batch/s, Train Accuracy=0.958, Train loss=0.0978]\n",
      "Epoch 39/100: 5001batch [01:25, 58.23batch/s, Train Accuracy=0.958, Train loss=0.0949]\n",
      "Epoch 40/100: 5001batch [01:25, 58.21batch/s, Train Accuracy=0.958, Train loss=0.0963]\n",
      "Epoch 41/100: 5001batch [01:26, 57.96batch/s, Train Accuracy=0.958, Train loss=0.0961]\n",
      "Epoch 42/100: 5001batch [01:26, 58.14batch/s, Train Accuracy=0.958, Train loss=0.0948]\n",
      "Epoch 43/100: 5001batch [01:26, 58.09batch/s, Train Accuracy=0.958, Train loss=0.0949]\n",
      "Epoch 44/100: 5001batch [01:26, 57.97batch/s, Train Accuracy=0.958, Train loss=0.0937]\n",
      "Epoch 45/100: 5001batch [01:25, 58.24batch/s, Train Accuracy=0.959, Train loss=0.0914]\n",
      "Epoch 46/100: 5001batch [01:26, 58.06batch/s, Train Accuracy=0.959, Train loss=0.0933]\n",
      "Epoch 47/100: 5001batch [01:26, 58.10batch/s, Train Accuracy=0.959, Train loss=0.0929]\n",
      "Epoch 48/100: 5001batch [01:26, 58.01batch/s, Train Accuracy=0.959, Train loss=0.0953]\n",
      "Epoch 49/100: 5001batch [01:31, 54.79batch/s, Train Accuracy=0.959, Train loss=0.0934]\n",
      "Epoch 50/100: 5001batch [01:31, 54.64batch/s, Train Accuracy=0.959, Train loss=0.0936]\n",
      "Epoch 51/100: 5001batch [01:31, 54.68batch/s, Train Accuracy=0.959, Train loss=0.0931]\n",
      "Epoch 52/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.959, Train loss=0.0939]\n",
      "Epoch 53/100: 5001batch [01:31, 54.60batch/s, Train Accuracy=0.959, Train loss=0.0929]\n",
      "Epoch 54/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.959, Train loss=0.0944]\n",
      "Epoch 55/100: 5001batch [01:31, 54.61batch/s, Train Accuracy=0.959, Train loss=0.0961]\n",
      "Epoch 56/100: 5001batch [01:31, 54.74batch/s, Train Accuracy=0.96, Train loss=0.0929]\n",
      "Epoch 57/100: 5001batch [01:31, 54.60batch/s, Train Accuracy=0.96, Train loss=0.0917]\n",
      "Epoch 58/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.96, Train loss=0.0907]\n",
      "Epoch 59/100: 5001batch [01:31, 54.68batch/s, Train Accuracy=0.96, Train loss=0.0919]\n",
      "Epoch 60/100: 5001batch [01:31, 54.74batch/s, Train Accuracy=0.96, Train loss=0.0913]\n",
      "Epoch 61/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.96, Train loss=0.0924]\n",
      "Epoch 62/100: 5001batch [01:30, 54.96batch/s, Train Accuracy=0.96, Train loss=0.0959]\n",
      "Epoch 63/100: 5001batch [01:30, 54.96batch/s, Train Accuracy=0.96, Train loss=0.0911]\n",
      "Epoch 64/100: 5001batch [01:30, 54.99batch/s, Train Accuracy=0.96, Train loss=0.0935]\n",
      "Epoch 65/100: 5001batch [01:30, 55.05batch/s, Train Accuracy=0.96, Train loss=0.0928]\n",
      "Epoch 66/100: 5001batch [01:31, 54.95batch/s, Train Accuracy=0.96, Train loss=0.0896]\n",
      "Epoch 67/100: 5001batch [01:30, 55.02batch/s, Train Accuracy=0.96, Train loss=0.0928]\n",
      "Epoch 68/100: 5001batch [01:30, 55.09batch/s, Train Accuracy=0.96, Train loss=0.0943]\n",
      "Epoch 69/100: 5001batch [01:30, 54.99batch/s, Train Accuracy=0.96, Train loss=0.0872]\n",
      "Epoch 70/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.96, Train loss=0.0893]\n",
      "Epoch 71/100: 5001batch [01:31, 54.94batch/s, Train Accuracy=0.961, Train loss=0.0913]\n",
      "Epoch 72/100: 5001batch [01:30, 54.96batch/s, Train Accuracy=0.961, Train loss=0.0908]\n",
      "Epoch 73/100: 5001batch [01:31, 54.88batch/s, Train Accuracy=0.961, Train loss=0.0922]\n",
      "Epoch 74/100: 5001batch [01:30, 54.96batch/s, Train Accuracy=0.961, Train loss=0.0898]\n",
      "Epoch 75/100: 5001batch [01:31, 54.91batch/s, Train Accuracy=0.961, Train loss=0.0931]\n",
      "Epoch 76/100: 5001batch [01:31, 54.95batch/s, Train Accuracy=0.961, Train loss=0.0894]\n",
      "Epoch 77/100: 5001batch [01:31, 54.95batch/s, Train Accuracy=0.961, Train loss=0.0904]\n",
      "Epoch 78/100: 5001batch [01:31, 54.95batch/s, Train Accuracy=0.961, Train loss=0.086]\n",
      "Epoch 79/100: 5001batch [01:31, 54.89batch/s, Train Accuracy=0.961, Train loss=0.091]\n",
      "Epoch 80/100: 5001batch [01:31, 54.86batch/s, Train Accuracy=0.961, Train loss=0.0886]\n",
      "Epoch 81/100: 5001batch [01:30, 55.06batch/s, Train Accuracy=0.961, Train loss=0.0919]\n",
      "Epoch 82/100: 5001batch [01:30, 55.05batch/s, Train Accuracy=0.961, Train loss=0.0904]\n",
      "Epoch 83/100: 5001batch [01:30, 55.03batch/s, Train Accuracy=0.961, Train loss=0.089]\n",
      "Epoch 84/100: 5001batch [01:30, 55.06batch/s, Train Accuracy=0.961, Train loss=0.091]\n",
      "Epoch 85/100: 5001batch [01:30, 55.08batch/s, Train Accuracy=0.961, Train loss=0.0886]\n",
      "Epoch 86/100: 5001batch [01:30, 54.96batch/s, Train Accuracy=0.961, Train loss=0.0902]\n",
      "Epoch 87/100: 5001batch [01:30, 55.00batch/s, Train Accuracy=0.961, Train loss=0.0887]\n",
      "Epoch 88/100: 5001batch [01:31, 54.92batch/s, Train Accuracy=0.961, Train loss=0.091]\n",
      "Epoch 89/100: 5001batch [01:31, 54.94batch/s, Train Accuracy=0.961, Train loss=0.0871]\n",
      "Epoch 90/100: 5001batch [01:30, 55.00batch/s, Train Accuracy=0.961, Train loss=0.0915]\n",
      "Epoch 91/100: 5001batch [01:31, 54.93batch/s, Train Accuracy=0.962, Train loss=0.0875]\n",
      "Epoch 92/100: 5001batch [01:31, 54.93batch/s, Train Accuracy=0.962, Train loss=0.0884]\n",
      "Epoch 93/100: 5001batch [01:31, 54.88batch/s, Train Accuracy=0.962, Train loss=0.0897]\n",
      "Epoch 94/100: 5001batch [01:31, 54.95batch/s, Train Accuracy=0.962, Train loss=0.0875]\n",
      "Epoch 95/100: 5001batch [01:30, 54.97batch/s, Train Accuracy=0.962, Train loss=0.0887]\n",
      "Epoch 96/100: 5001batch [01:31, 54.93batch/s, Train Accuracy=0.962, Train loss=0.0915]\n",
      "Epoch 97/100: 5001batch [01:31, 54.91batch/s, Train Accuracy=0.962, Train loss=0.0883]\n",
      "Epoch 98/100: 5001batch [01:30, 55.00batch/s, Train Accuracy=0.962, Train loss=0.0879]\n",
      "Epoch 99/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.962, Train loss=0.0888]\n",
      "Epoch 100/100: 5001batch [01:31, 54.87batch/s, Train Accuracy=0.962, Train loss=0.0878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained models have been saved as: \n",
      "fpm_models/fpm_conv_2skip_worm3_180_deg.h5\n"
     ]
    }
   ],
   "source": [
    "points_path=\"./worm3_points_t1.csv\"\n",
    "model_name=\"fpm_conv_2skip_worm3_180_deg\"\n",
    "deg = 180\n",
    "num_epochs=100\n",
    "match_model = FlexiblePointMatcherConv(num_skip=2)\n",
    "\n",
    "fpm_trainer = TrainFPM(points1_path=points_path, match_model=match_model, model_name=model_name, \n",
    "                       range_rotation_tgt=deg)\n",
    "fpm_trainer.train(num_epochs=num_epochs, iteration=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1251a285",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 5001batch [01:26, 58.12batch/s, Train Accuracy=0.955, Train loss=0.0623]\n",
      "Epoch 2/100: 5001batch [01:26, 58.00batch/s, Train Accuracy=0.979, Train loss=0.0419]\n",
      "Epoch 3/100: 5001batch [01:25, 58.23batch/s, Train Accuracy=0.982, Train loss=0.0384]\n",
      "Epoch 4/100: 5001batch [01:26, 58.13batch/s, Train Accuracy=0.983, Train loss=0.036]\n",
      "Epoch 5/100: 5001batch [01:26, 58.06batch/s, Train Accuracy=0.984, Train loss=0.0353]\n",
      "Epoch 6/100: 5001batch [01:26, 58.14batch/s, Train Accuracy=0.985, Train loss=0.0346]\n",
      "Epoch 7/100: 5001batch [01:26, 58.14batch/s, Train Accuracy=0.985, Train loss=0.0341]\n",
      "Epoch 8/100: 5001batch [01:25, 58.16batch/s, Train Accuracy=0.986, Train loss=0.0331]\n",
      "Epoch 9/100: 5001batch [01:26, 57.90batch/s, Train Accuracy=0.986, Train loss=0.0326]\n",
      "Epoch 10/100: 5001batch [01:25, 58.17batch/s, Train Accuracy=0.986, Train loss=0.0311]\n",
      "Epoch 11/100: 5001batch [01:26, 58.12batch/s, Train Accuracy=0.987, Train loss=0.0316]\n",
      "Epoch 12/100: 5001batch [01:26, 58.08batch/s, Train Accuracy=0.987, Train loss=0.0315]\n",
      "Epoch 13/100: 5001batch [01:26, 58.12batch/s, Train Accuracy=0.987, Train loss=0.0306]\n",
      "Epoch 14/100: 5001batch [01:26, 58.03batch/s, Train Accuracy=0.987, Train loss=0.0301]\n",
      "Epoch 15/100: 5001batch [01:26, 57.89batch/s, Train Accuracy=0.987, Train loss=0.0303]\n",
      "Epoch 16/100: 5001batch [01:26, 57.87batch/s, Train Accuracy=0.987, Train loss=0.0301]\n",
      "Epoch 17/100: 5001batch [01:26, 58.03batch/s, Train Accuracy=0.988, Train loss=0.0289]\n",
      "Epoch 18/100: 5001batch [01:25, 58.16batch/s, Train Accuracy=0.988, Train loss=0.0282]\n",
      "Epoch 19/100: 5001batch [01:26, 57.97batch/s, Train Accuracy=0.988, Train loss=0.0284]\n",
      "Epoch 20/100: 5001batch [01:26, 57.97batch/s, Train Accuracy=0.988, Train loss=0.0276]\n",
      "Epoch 21/100: 5001batch [01:26, 58.12batch/s, Train Accuracy=0.988, Train loss=0.0274]\n",
      "Epoch 22/100: 5001batch [01:26, 57.89batch/s, Train Accuracy=0.988, Train loss=0.0262]\n",
      "Epoch 23/100: 5001batch [01:26, 57.97batch/s, Train Accuracy=0.988, Train loss=0.0265]\n",
      "Epoch 24/100: 5001batch [01:26, 58.01batch/s, Train Accuracy=0.988, Train loss=0.0263]\n",
      "Epoch 25/100: 5001batch [01:26, 58.14batch/s, Train Accuracy=0.988, Train loss=0.0263]\n",
      "Epoch 26/100: 5001batch [01:26, 58.03batch/s, Train Accuracy=0.989, Train loss=0.0262]\n",
      "Epoch 27/100: 5001batch [01:26, 58.03batch/s, Train Accuracy=0.989, Train loss=0.0259]\n",
      "Epoch 28/100: 5001batch [01:25, 58.24batch/s, Train Accuracy=0.989, Train loss=0.0258]\n",
      "Epoch 29/100: 5001batch [01:26, 57.98batch/s, Train Accuracy=0.989, Train loss=0.0261]\n",
      "Epoch 30/100: 5001batch [01:26, 58.12batch/s, Train Accuracy=0.989, Train loss=0.0252]\n",
      "Epoch 31/100: 5001batch [01:26, 58.14batch/s, Train Accuracy=0.989, Train loss=0.0248]\n",
      "Epoch 32/100: 5001batch [01:26, 58.14batch/s, Train Accuracy=0.989, Train loss=0.0255]\n",
      "Epoch 33/100: 5001batch [01:26, 58.11batch/s, Train Accuracy=0.989, Train loss=0.0252]\n",
      "Epoch 34/100: 5001batch [01:31, 54.79batch/s, Train Accuracy=0.989, Train loss=0.0242]\n",
      "Epoch 35/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.989, Train loss=0.0246]\n",
      "Epoch 36/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.99, Train loss=0.0252]\n",
      "Epoch 37/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.99, Train loss=0.024]\n",
      "Epoch 38/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.99, Train loss=0.0244]\n",
      "Epoch 39/100: 5001batch [01:31, 54.70batch/s, Train Accuracy=0.99, Train loss=0.0237]\n",
      "Epoch 40/100: 5001batch [01:31, 54.69batch/s, Train Accuracy=0.99, Train loss=0.0232]\n",
      "Epoch 41/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.99, Train loss=0.0245]\n",
      "Epoch 42/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.99, Train loss=0.0227]\n",
      "Epoch 43/100: 5001batch [01:31, 54.68batch/s, Train Accuracy=0.99, Train loss=0.0236]\n",
      "Epoch 44/100: 5001batch [01:31, 54.81batch/s, Train Accuracy=0.99, Train loss=0.0239]\n",
      "Epoch 45/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.99, Train loss=0.0234]\n",
      "Epoch 46/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.99, Train loss=0.0233]\n",
      "Epoch 47/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.99, Train loss=0.0231]\n",
      "Epoch 48/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.99, Train loss=0.024]\n",
      "Epoch 49/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.99, Train loss=0.0231]\n",
      "Epoch 50/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.991, Train loss=0.0234]\n",
      "Epoch 51/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.991, Train loss=0.0217]\n",
      "Epoch 52/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.991, Train loss=0.0229]\n",
      "Epoch 53/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.991, Train loss=0.0226]\n",
      "Epoch 54/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.991, Train loss=0.0234]\n",
      "Epoch 55/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.991, Train loss=0.0232]\n",
      "Epoch 56/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.991, Train loss=0.022]\n",
      "Epoch 57/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.991, Train loss=0.0233]\n",
      "Epoch 58/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.991, Train loss=0.0223]\n",
      "Epoch 59/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.991, Train loss=0.0229]\n",
      "Epoch 60/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.991, Train loss=0.0229]\n",
      "Epoch 61/100: 5001batch [01:31, 54.86batch/s, Train Accuracy=0.991, Train loss=0.0231]\n",
      "Epoch 62/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.991, Train loss=0.0218]\n",
      "Epoch 63/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.992, Train loss=0.0225]\n",
      "Epoch 64/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.992, Train loss=0.0225]\n",
      "Epoch 65/100: 5001batch [01:31, 54.79batch/s, Train Accuracy=0.992, Train loss=0.0223]\n",
      "Epoch 66/100: 5001batch [01:31, 54.69batch/s, Train Accuracy=0.992, Train loss=0.0223]\n",
      "Epoch 67/100: 5001batch [01:31, 54.81batch/s, Train Accuracy=0.992, Train loss=0.022]\n",
      "Epoch 68/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.992, Train loss=0.0219]\n",
      "Epoch 69/100: 5001batch [01:31, 54.91batch/s, Train Accuracy=0.992, Train loss=0.0223]\n",
      "Epoch 70/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.992, Train loss=0.0217]\n",
      "Epoch 71/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.992, Train loss=0.022]\n",
      "Epoch 72/100: 5001batch [01:31, 54.86batch/s, Train Accuracy=0.992, Train loss=0.0222]\n",
      "Epoch 73/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.992, Train loss=0.0216]\n",
      "Epoch 74/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.992, Train loss=0.0217]\n",
      "Epoch 75/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.992, Train loss=0.0215]\n",
      "Epoch 76/100: 5001batch [01:31, 54.74batch/s, Train Accuracy=0.992, Train loss=0.0213]\n",
      "Epoch 77/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.992, Train loss=0.0214]\n",
      "Epoch 78/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.992, Train loss=0.0221]\n",
      "Epoch 79/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.992, Train loss=0.0219]\n",
      "Epoch 80/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.993, Train loss=0.0217]\n",
      "Epoch 81/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.993, Train loss=0.021]\n",
      "Epoch 82/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.993, Train loss=0.0211]\n",
      "Epoch 83/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.993, Train loss=0.0217]\n",
      "Epoch 84/100: 5001batch [01:31, 54.83batch/s, Train Accuracy=0.993, Train loss=0.0208]\n",
      "Epoch 85/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.993, Train loss=0.0217]\n",
      "Epoch 86/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.993, Train loss=0.0216]\n",
      "Epoch 87/100: 5001batch [01:31, 54.79batch/s, Train Accuracy=0.993, Train loss=0.0204]\n",
      "Epoch 88/100: 5001batch [01:31, 54.87batch/s, Train Accuracy=0.993, Train loss=0.021]\n",
      "Epoch 89/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.993, Train loss=0.0208]\n",
      "Epoch 90/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.993, Train loss=0.0209]\n",
      "Epoch 91/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.993, Train loss=0.0209]\n",
      "Epoch 92/100: 5001batch [01:31, 54.81batch/s, Train Accuracy=0.993, Train loss=0.0204]\n",
      "Epoch 93/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.993, Train loss=0.0205]\n",
      "Epoch 94/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.993, Train loss=0.0201]\n",
      "Epoch 95/100: 5001batch [01:30, 55.01batch/s, Train Accuracy=0.993, Train loss=0.0209]\n",
      "Epoch 96/100: 5001batch [01:31, 54.92batch/s, Train Accuracy=0.993, Train loss=0.0205]\n",
      "Epoch 97/100: 5001batch [01:30, 54.96batch/s, Train Accuracy=0.993, Train loss=0.0208]\n",
      "Epoch 98/100: 5001batch [01:30, 54.99batch/s, Train Accuracy=0.993, Train loss=0.0208]\n",
      "Epoch 99/100: 5001batch [01:31, 54.87batch/s, Train Accuracy=0.993, Train loss=0.0203]\n",
      "Epoch 100/100: 5001batch [01:31, 54.93batch/s, Train Accuracy=0.993, Train loss=0.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained models have been saved as: \n",
      "fpm_models/fpm_conv_2skip_worm3_10_deg.h5\n"
     ]
    }
   ],
   "source": [
    "points_path=\"./worm3_points_t1.csv\"\n",
    "model_name=\"fpm_conv_2skip_worm3_10_deg\"\n",
    "deg = 10\n",
    "num_epochs=100\n",
    "match_model = FlexiblePointMatcherConv(num_skip=2)\n",
    "\n",
    "fpm_trainer = TrainFPM(points1_path=points_path, match_model=match_model, model_name=model_name, \n",
    "                       range_rotation_tgt=deg)\n",
    "fpm_trainer.train(num_epochs=num_epochs, iteration=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46858d",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# points_path=\"./worm3_points_t1.csv\"\n",
    "model_name=\"fpm_add_worm3_180_deg\"\n",
    "deg = (-180, 180)\n",
    "\n",
    "fpm_trainer = TrainFPM(points1_path=points_path, model_type=\"add\", model_name=model_name, range_rotation_ref=deg, range_rotation_tgt=deg)\n",
    "num_epochs=100\n",
    "\n",
    "fpm_trainer.train(num_epochs=num_epochs, iteration=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca07094c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.872, Train loss=0.191]\n",
      "Epoch 2/100: 5001batch [01:31, 54.79batch/s, Train Accuracy=0.929, Train loss=0.129]\n",
      "Epoch 3/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.938, Train loss=0.125]\n",
      "Epoch 4/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.942, Train loss=0.12]\n",
      "Epoch 5/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.945, Train loss=0.116]\n",
      "Epoch 6/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.947, Train loss=0.106]\n",
      "Epoch 7/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.949, Train loss=0.104]\n",
      "Epoch 8/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.951, Train loss=0.0969]\n",
      "Epoch 9/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.952, Train loss=0.0959]\n",
      "Epoch 10/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.953, Train loss=0.0931]\n",
      "Epoch 11/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.954, Train loss=0.0942]\n",
      "Epoch 12/100: 5001batch [01:31, 54.81batch/s, Train Accuracy=0.955, Train loss=0.0902]\n",
      "Epoch 13/100: 5001batch [01:31, 54.79batch/s, Train Accuracy=0.956, Train loss=0.0909]\n",
      "Epoch 14/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.957, Train loss=0.0874]\n",
      "Epoch 15/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.957, Train loss=0.0912]\n",
      "Epoch 16/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.958, Train loss=0.0896]\n",
      "Epoch 17/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.958, Train loss=0.0893]\n",
      "Epoch 18/100: 5001batch [01:31, 54.83batch/s, Train Accuracy=0.959, Train loss=0.0884]\n",
      "Epoch 19/100: 5001batch [01:31, 54.81batch/s, Train Accuracy=0.959, Train loss=0.088]\n",
      "Epoch 20/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.96, Train loss=0.0858]\n",
      "Epoch 21/100: 5001batch [01:31, 54.74batch/s, Train Accuracy=0.96, Train loss=0.0848]\n",
      "Epoch 22/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.96, Train loss=0.0873]\n",
      "Epoch 23/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.961, Train loss=0.0869]\n",
      "Epoch 24/100: 5001batch [01:31, 54.67batch/s, Train Accuracy=0.961, Train loss=0.0849]\n",
      "Epoch 25/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.961, Train loss=0.0884]\n",
      "Epoch 26/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.961, Train loss=0.0842]\n",
      "Epoch 27/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.962, Train loss=0.084]\n",
      "Epoch 28/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.962, Train loss=0.0841]\n",
      "Epoch 29/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.962, Train loss=0.0832]\n",
      "Epoch 30/100: 5001batch [01:31, 54.84batch/s, Train Accuracy=0.962, Train loss=0.0833]\n",
      "Epoch 31/100: 5001batch [01:31, 54.83batch/s, Train Accuracy=0.962, Train loss=0.0829]\n",
      "Epoch 32/100: 5001batch [01:31, 54.90batch/s, Train Accuracy=0.963, Train loss=0.084]\n",
      "Epoch 33/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.963, Train loss=0.0839]\n",
      "Epoch 34/100: 5001batch [01:31, 54.86batch/s, Train Accuracy=0.963, Train loss=0.0839]\n",
      "Epoch 35/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.963, Train loss=0.0837]\n",
      "Epoch 36/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.963, Train loss=0.0827]\n",
      "Epoch 37/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.963, Train loss=0.0841]\n",
      "Epoch 38/100: 5001batch [01:31, 54.86batch/s, Train Accuracy=0.963, Train loss=0.0824]\n",
      "Epoch 39/100: 5001batch [01:31, 54.83batch/s, Train Accuracy=0.964, Train loss=0.0847]\n",
      "Epoch 40/100: 5001batch [01:31, 54.68batch/s, Train Accuracy=0.964, Train loss=0.0823]\n",
      "Epoch 41/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.964, Train loss=0.0812]\n",
      "Epoch 42/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.964, Train loss=0.0825]\n",
      "Epoch 43/100: 5001batch [01:31, 54.70batch/s, Train Accuracy=0.964, Train loss=0.0831]\n",
      "Epoch 44/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.964, Train loss=0.0812]\n",
      "Epoch 45/100: 5001batch [01:31, 54.74batch/s, Train Accuracy=0.964, Train loss=0.0821]\n",
      "Epoch 46/100: 5001batch [01:31, 54.69batch/s, Train Accuracy=0.964, Train loss=0.0797]\n",
      "Epoch 47/100: 5001batch [01:31, 54.66batch/s, Train Accuracy=0.964, Train loss=0.0773]\n",
      "Epoch 48/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.965, Train loss=0.082]\n",
      "Epoch 49/100: 5001batch [01:31, 54.68batch/s, Train Accuracy=0.965, Train loss=0.0827]\n",
      "Epoch 50/100: 5001batch [01:31, 54.59batch/s, Train Accuracy=0.965, Train loss=0.0812]\n",
      "Epoch 51/100: 5001batch [01:31, 54.81batch/s, Train Accuracy=0.965, Train loss=0.0827]\n",
      "Epoch 52/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.965, Train loss=0.0793]\n",
      "Epoch 53/100: 5001batch [01:31, 54.83batch/s, Train Accuracy=0.965, Train loss=0.0782]\n",
      "Epoch 54/100: 5001batch [01:31, 54.85batch/s, Train Accuracy=0.965, Train loss=0.0779]\n",
      "Epoch 55/100: 5001batch [01:31, 54.69batch/s, Train Accuracy=0.965, Train loss=0.0807]\n",
      "Epoch 56/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.965, Train loss=0.0827]\n",
      "Epoch 57/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.965, Train loss=0.0825]\n",
      "Epoch 58/100: 5001batch [01:31, 54.75batch/s, Train Accuracy=0.965, Train loss=0.0832]\n",
      "Epoch 59/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.965, Train loss=0.08]\n",
      "Epoch 60/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.965, Train loss=0.0785]\n",
      "Epoch 61/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.966, Train loss=0.0779]\n",
      "Epoch 62/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.966, Train loss=0.084]\n",
      "Epoch 63/100: 5001batch [01:31, 54.61batch/s, Train Accuracy=0.966, Train loss=0.0803]\n",
      "Epoch 64/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.966, Train loss=0.0821]\n",
      "Epoch 65/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.966, Train loss=0.0812]\n",
      "Epoch 66/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.966, Train loss=0.0785]\n",
      "Epoch 67/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.966, Train loss=0.0787]\n",
      "Epoch 68/100: 5001batch [01:31, 54.68batch/s, Train Accuracy=0.966, Train loss=0.0784]\n",
      "Epoch 69/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.966, Train loss=0.0771]\n",
      "Epoch 70/100: 5001batch [01:31, 54.63batch/s, Train Accuracy=0.966, Train loss=0.0785]\n",
      "Epoch 71/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.966, Train loss=0.0792]\n",
      "Epoch 72/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.966, Train loss=0.0788]\n",
      "Epoch 73/100: 5001batch [01:31, 54.42batch/s, Train Accuracy=0.966, Train loss=0.081]\n",
      "Epoch 74/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.966, Train loss=0.0789]\n",
      "Epoch 75/100: 5001batch [01:31, 54.78batch/s, Train Accuracy=0.966, Train loss=0.0794]\n",
      "Epoch 76/100: 5001batch [01:31, 54.70batch/s, Train Accuracy=0.966, Train loss=0.0771]\n",
      "Epoch 77/100: 5001batch [01:31, 54.72batch/s, Train Accuracy=0.966, Train loss=0.0803]\n",
      "Epoch 78/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.966, Train loss=0.0779]\n",
      "Epoch 79/100: 5001batch [01:31, 54.82batch/s, Train Accuracy=0.967, Train loss=0.076]\n",
      "Epoch 80/100: 5001batch [01:31, 54.65batch/s, Train Accuracy=0.967, Train loss=0.0786]\n",
      "Epoch 81/100: 5001batch [01:31, 54.73batch/s, Train Accuracy=0.967, Train loss=0.0776]\n",
      "Epoch 82/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.967, Train loss=0.0774]\n",
      "Epoch 83/100: 5001batch [01:31, 54.77batch/s, Train Accuracy=0.967, Train loss=0.0771]\n",
      "Epoch 84/100: 5001batch [01:31, 54.70batch/s, Train Accuracy=0.967, Train loss=0.0777]\n",
      "Epoch 85/100: 5001batch [01:31, 54.76batch/s, Train Accuracy=0.967, Train loss=0.0785]\n",
      "Epoch 86/100: 5001batch [01:31, 54.62batch/s, Train Accuracy=0.967, Train loss=0.077]\n",
      "Epoch 87/100: 5001batch [01:31, 54.68batch/s, Train Accuracy=0.967, Train loss=0.0809]\n",
      "Epoch 88/100: 5001batch [01:31, 54.64batch/s, Train Accuracy=0.967, Train loss=0.0768]\n",
      "Epoch 89/100: 5001batch [01:31, 54.64batch/s, Train Accuracy=0.967, Train loss=0.0752]\n",
      "Epoch 90/100: 5001batch [01:31, 54.74batch/s, Train Accuracy=0.967, Train loss=0.0759]\n",
      "Epoch 91/100: 5001batch [01:31, 54.66batch/s, Train Accuracy=0.967, Train loss=0.0775]\n",
      "Epoch 92/100: 5001batch [01:31, 54.74batch/s, Train Accuracy=0.967, Train loss=0.0774]\n",
      "Epoch 93/100: 5001batch [01:31, 54.69batch/s, Train Accuracy=0.967, Train loss=0.0762]\n",
      "Epoch 94/100: 5001batch [01:31, 54.71batch/s, Train Accuracy=0.967, Train loss=0.0762]\n",
      "Epoch 95/100: 5001batch [01:31, 54.83batch/s, Train Accuracy=0.967, Train loss=0.0745]\n",
      "Epoch 96/100: 5001batch [01:31, 54.80batch/s, Train Accuracy=0.967, Train loss=0.0775]\n",
      "Epoch 97/100: 5001batch [01:31, 54.87batch/s, Train Accuracy=0.967, Train loss=0.0752]\n",
      "Epoch 98/100: 5001batch [01:31, 54.83batch/s, Train Accuracy=0.967, Train loss=0.0769]\n",
      "Epoch 99/100: 5001batch [01:31, 54.81batch/s, Train Accuracy=0.967, Train loss=0.0775]\n",
      "Epoch 100/100: 5001batch [01:31, 54.89batch/s, Train Accuracy=0.967, Train loss=0.0756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained models have been saved as: \n",
      "fpm_models/fpm_conv_2skip_worm3_90_deg.h5\n"
     ]
    }
   ],
   "source": [
    "points_path=\"./worm3_points_t1.csv\"\n",
    "model_name=\"fpm_conv_2skip_worm3_90_deg\"\n",
    "deg = 90\n",
    "num_epochs=100\n",
    "match_model = FlexiblePointMatcherConv(num_skip=2)\n",
    "\n",
    "fpm_trainer = TrainFPM(points1_path=points_path, match_model=match_model, model_name=model_name, \n",
    "                       range_rotation_tgt=deg)\n",
    "fpm_trainer.train(num_epochs=num_epochs, iteration=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708580f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
